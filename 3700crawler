#!/usr/bin/env python3

import argparse
import socket
import ssl
from html.parser import HTMLParser
from urllib.parse import urlparse

DEFAULT_SERVER = "www.3700.network"
DEFAULT_PORT = 443
HTTP_VERSION = "1.1"

visited_links = []
link_set = set({}) # set
flags = []

class MyHTMLParser(HTMLParser):
    def handle_starttag(self, tag, attrs):
        if (tag == 'a'):
            for key, value in attrs:
                if key == "href" and value is not None and value not in visited_links and '/fakebook/' in value:
                    link_set.add(value) # if a duplicate link is added, it does not get added to the set  

    def handle_data(self, data):
        if (data.startswith("FLAG:")):
            flags.append(data)

class Crawler:
    def __init__(self, args):
        self.server = args.server
        self.port = args.port
        self.username = args.username
        self.password = args.password
        self.csrf_token = None
        self.session_id = None
        self.socket = None

    def init_connection(self):
        # creating + wrapping the socket
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
        context.load_default_certs()
        mysocket = context.wrap_socket(sock, server_hostname=self.server)
        # establishing socket connection with server
        mysocket.connect((self.server, self.port))
        
        self.socket = mysocket
        

    def login(self):
        # GET the login page
        request = f"GET /accounts/login/?next=/fakebook/ HTTP/{HTTP_VERSION}\r\nHost: {self.server}\r\n\r\n"
        response = self.send_request(request)
        self.get_cookies(response)

        # enter login credentials
        login_credentials = f"username={self.username}&password={self.password}&csrfmiddlewaretoken={self.csrf_token}&next=/fakebook/"
        login_cred_length = len(login_credentials)

        # POST the login information
        request = f"POST /accounts/login/ HTTP/{HTTP_VERSION}\r\nHost: {self.server}\r\nContent-Type: application/x-www-form-urlencoded\r\nCookie: csrftoken={self.csrf_token}; sessionid={self.session_id}\r\nContent-Length: {login_cred_length}\r\n\r\n{login_credentials}"
        response = self.send_request(request)
        self.get_cookies(response)

        return response
        

    def get_cookies(self, response):
        # obtaining the csrf token
        [csrf_cookie] = list(filter(lambda x: x.startswith("csrftoken="), response["cookies"]))
        self.csrf_token = csrf_cookie.split("; ")[0].split("=")[1]

        # obtaining the session id
        [session_id_cookie] = list(filter(lambda x: x.startswith("sessionid="), response["cookies"]))
        self.session_id = session_id_cookie.split("; ")[0].split("=")[1]
		
		
    def send_request(self, request):
        self.init_connection()

        self.socket.send(request.encode('ascii'))

        # receiving data
        response = self.socket.recv(100000)
        response_data = response.decode('utf-8')

        self.socket.close()

        return self.parse_http_response(response_data)
    
    def parse_http_response(self, response_data):
        # Remove trailing whitespace and isolate the respone (separate it from HTML content)
        data = response_data.strip().split("\r\n\r\n")

        response = {}
        headers = data[0].split("\r\n")

        # extracts status code
        response["status_code"] = int(headers[0].split(" ")[1])

        response["header_fields"] = {}
        response["cookies"] = []
        for header in headers[1:]:
            (field, content) = header.split(": ")
            if field == "set-cookie":
                response["cookies"].append(content)
            else:
                response["header_fields"][field] = content

        # if "Transfer-Encoding" in response["header_fields"].keys():
        #     if (response["header_fields"]["Transfer-Encoding"] == "chunked"):
        #         # print("---------------------\n\nEncountered Chunked Encoding\n\n---------------------")
        #         body_tmp = data[-1].strip().split("\r\n")

        #         body = ""
        #         for n in range(len(body_tmp)):
        #             if n % 2 == 0:
        #                 if body_tmp[n] == "0":
        #                     break
        #                 else:
        #                     pass
        #             else:
        #                 body += body_tmp[n]
        # else:
        response["body"] = data[-1] if data else None

        return response

    def run(self):
        response = self.login()

        request = f"GET {response['header_fields']['location']} HTTP/{HTTP_VERSION}\r\nHost: www.3700.network\r\nCookie: csrftoken={self.csrf_token}; sessionid={self.session_id}\r\n\r\n"
        response = self.send_request(request)

        parser = MyHTMLParser()
        parser.feed(response["body"])

        while (len(link_set) > 0 and len(flags) < 5):
            current_link = link_set.pop()
            
            request = self.get_request(link=current_link, csrf=self.csrf_token, session_id=self.session_id)
            # print("------------------------")
            # print(request)
            # print("------------------------")
            # print("Request: %s" % request)
            response = self.send_request(request)
            visited_links.append(current_link)



            if (response["status_code"] == 200):
                parser.feed(response["body"])
                # print(("# Links Visited: %s" % len(visited_links)).ljust(30, " ") + 
                #     ("# Links To Visit: %s" % len(link_set)).ljust(30, " ") + 
                #     ("Visiting: %s" % current_link))
            elif (response["status_code"] == 302):
                link_set.add(response["header_fields"]["location"])
            elif (response["status_code"] in (400, 403, 404)):
                pass
            elif (response["status_code"] == 503):
                link_set.add(current_link)
            else:
                raise Exception(f"Unrecognized status code: {response} caused by request {request}")

        for flag in flags:
            print(flag.replace("FLAG: ", ""), "\n")
            # sys.stdout.write(flag.replace("FLAG: ", ""), "\n")
    
    def get_request(self, link, csrf=None, session_id=None):
        link = urlparse(link)

        request = "GET "
        request += f"{link.path} "
        request += f"HTTP/{HTTP_VERSION}\r\n"
        request += f"HOST: {self.server}\r\n"

        if csrf != None and session_id != None:
            request += f"Cookie: csrftoken={csrf}; "
            request += f"sessionid={session_id}\r\n"

        request += "\r\n"
        return request


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='crawl Fakebook')
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()
    sender = Crawler(args)
    sender.run()
